{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihankr/ml-sentiment-analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpr_GVUonWxW"
      },
      "source": [
        "# Dicoding - Projek Analisis Sentimen\n",
        "Dibuat oleh: Raihan Khairul Rochman\n",
        "\n",
        "**Objektif:**  \n",
        "Menganalisis sentimen pada ulasan pengguna terhadap aplikasi **SATUSEHAT Mobile** di Play Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j28-4b7En2V3"
      },
      "source": [
        "# Impor *Library*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJhayuUn1wJ",
        "outputId": "2b3d23b7-1d61-4f75-f064-a557d9345afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google_play_scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google_play_scraper\n",
            "Successfully installed google_play_scraper-1.2.7\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install google_play_scraper\n",
        "!pip install Sastrawi\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from google_play_scraper import Sort, reviews\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import json\n",
        "import requests\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjc4yU7HoCmG"
      },
      "source": [
        "# *Data Scraping*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mM5EjCPLoJpw"
      },
      "outputs": [],
      "source": [
        "scraped_data, token = reviews(\n",
        "    'com.pinterest', ## SATUSEHAT Mobile\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort=Sort.MOST_RELEVANT,\n",
        "    count=15000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N2yMxQxf3_aX"
      },
      "outputs": [],
      "source": [
        "with open('drive/My Drive/reviews.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])\n",
        "    for review in scraped_data:\n",
        "        writer.writerow([review['content']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US9dX6gjD9WM"
      },
      "source": [
        "# Load & Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cEJ2SaSfBCK-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/My Drive/reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zC9RpL9dD41A"
      },
      "outputs": [],
      "source": [
        "df = df.dropna().drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsUvXZfh0OrU",
        "outputId": "8c4a0c5c-4b16-41c4-f005-3347444b05fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 14994 entries, 0 to 14999\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  14994 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 234.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqRXEHCm-q1"
      },
      "source": [
        "**Deskripsi Data**:\n",
        "Saya mengambil data dari sekitar 15.000  ulasan pengguna paling relevan terhadap aplikasi *SATUSEHAT Mobile* di *platform* Google Play Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZILyMOpWfih"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_BnS98DX2OxZ"
      },
      "outputs": [],
      "source": [
        "# Tambahan stopwords untuk bahasa Indonesia\n",
        "stopwords1 = pd.read_csv('https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/stopword.txt', header=None, names=['word'])\n",
        "stopwords1 = stopwords1['word'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KpSLVXGQ-zKc"
      },
      "outputs": [],
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt')\n",
        "slangwords = json.loads(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HNlsx5MgXyfr"
      },
      "outputs": [],
      "source": [
        "def cleanText(text):\n",
        "    result = re.sub(r\"(([@#]|https?:\\/\\/)\\S+|\\d|[^\\w\\s])\", \"\", text)\n",
        "    result.replace(\"\\n\", \" \")\n",
        "    result = result.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    result = result.strip(\" \")\n",
        "    return result\n",
        "\n",
        "casefoldingText = lambda text: text.lower()\n",
        "\n",
        "def fixSlangWords(words):\n",
        "    result = []\n",
        "    for word in words:\n",
        "        if word in slangwords:\n",
        "            result.append(slangwords[word])\n",
        "        else:\n",
        "            result.append(word)\n",
        "    return result\n",
        "\n",
        "def filterWords(words):\n",
        "    stopwords_list = set(stopwords.words('indonesian'))\n",
        "    stopwords_list.update(stopwords1)\n",
        "    stopwords_list.update(stopwords.words('english'))\n",
        "\n",
        "    result = []\n",
        "    for word in words:\n",
        "        if word not in stopwords_list:\n",
        "            result.append(word)\n",
        "    return result\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "stemWords = lambda text: stemmer.stem(text)\n",
        "\n",
        "toSentence = lambda words: ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2Y07gWsGFssR"
      },
      "outputs": [],
      "source": [
        "df['Clean'] = df['Review'].apply(cleanText).apply(casefoldingText)\n",
        "df['Tokenized'] = df['Clean'].apply(word_tokenize)\n",
        "df['Formalized'] = df['Tokenized'].apply(fixSlangWords)\n",
        "df['Stemmed'] = df['Formalized'].apply(toSentence).apply(lambda t: stemmer.stem(t))\n",
        "df['Filtered'] = df['Stemmed'].apply(filterWords)\n",
        "df['Final'] = df ['Filtered'].apply(toSentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqlxKIy9Xvmc"
      },
      "source": [
        "# Data Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7uU_-IOCM1e"
      },
      "outputs": [],
      "source": [
        "lexicon_positive = pd.read_csv('https://raw.githubusercontent.com/fajri91/InSet/master/positive.tsv', delimiter='\\t', index_col=0).T.loc['weight'].to_dict()\n",
        "lexicon_negative = pd.read_csv('https://raw.githubusercontent.com/fajri91/InSet/master/negative.tsv', delimiter='\\t', index_col=0).T.loc['weight'].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPTuYZQsOxk0"
      },
      "outputs": [],
      "source": [
        "def sentiment_analysis(words):\n",
        "    score = 0\n",
        "    for word in words:\n",
        "        if word in lexicon_positive:\n",
        "            score += lexicon_positive[word]\n",
        "        if word in lexicon_negative:\n",
        "            score += lexicon_negative[word]\n",
        "    polarity: str\n",
        "    if score >= 2:\n",
        "        polarity = 'positive'\n",
        "    elif score <= -2:\n",
        "        polarity = 'negative'\n",
        "    else:\n",
        "        polarity = 'neutral'\n",
        "    return score, polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SAu2wiKPkUY"
      },
      "outputs": [],
      "source": [
        "labeled = df['Filtered'].apply(sentiment_analysis)\n",
        "labeled = list(zip(*labeled))\n",
        "(df['Score'], df['Polarity']) = labeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8H_S1h4RgpI"
      },
      "outputs": [],
      "source": [
        "df[['Filtered', 'Polarity', 'Score']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK-x8jzBXyrs"
      },
      "outputs": [],
      "source": [
        "df['Polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7EMULyUavkv"
      },
      "outputs": [],
      "source": [
        "(X, y) = (df['Final'], df['Polarity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWpRBJOc7oUU"
      },
      "outputs": [],
      "source": [
        "X,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9FZW3RqwqfF"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW91dLFc1uzk"
      },
      "outputs": [],
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "stemmer.stem('menggunakan')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Clean'][0:100].apply(lambda t: stemmer.stem(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "jAUlrSQBQ_iY",
        "outputId": "95733a00-c5f7-4eb8-e0a5-66b6e86ab0f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    bagus tapi belakang ini suka loading lama bang...\n",
              "1    apk nya baguss baguss banget cocok buat altern...\n",
              "2    aplikasi sebenernya bagus tapi telah saya upda...\n",
              "3    untuk aplikasi sudah baik dan cukup tarik teta...\n",
              "4    update terbarupinterest cukup baikhanya saja a...\n",
              "5    ken nyari inspirasi di pinterest tapi baru mas...\n",
              "6    semua udh bagus tapi tolong dong loadingnya ak...\n",
              "7    turut pinterest nya udah bagus bisa nyari ide ...\n",
              "8    tolong baik untuk bug dan loading yang lebih l...\n",
              "9    saya sudah lama pakai app ini tapi saya kurang...\n",
              "Name: Clean, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bagus tapi belakang ini suka loading lama bang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apk nya baguss baguss banget cocok buat altern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aplikasi sebenernya bagus tapi telah saya upda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>untuk aplikasi sudah baik dan cukup tarik teta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>update terbarupinterest cukup baikhanya saja a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ken nyari inspirasi di pinterest tapi baru mas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>semua udh bagus tapi tolong dong loadingnya ak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>turut pinterest nya udah bagus bisa nyari ide ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tolong baik untuk bug dan loading yang lebih l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>saya sudah lama pakai app ini tapi saya kurang...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1VyG1oGPY64jhKvMtxAu42qlOHsAv9a5s",
      "authorship_tag": "ABX9TyNAVsvpoJhk4gElR8GUh/1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}